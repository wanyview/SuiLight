# SuiLight Knowledge Salon - 环境变量配置
# 复制此文件为 .env 并填入你的配置

# ============ LLM 配置 (选择一种即可) ============

# LLM 提供商: mock/ollama/groq/openai/minimax
LLM_PROVIDER=mock

# Groq (免费高速) - https://console.groq.cloud
GROQ_API_KEY=

# OpenAI (GPT-4) - https://platform.openai.com
OPENAI_API_KEY=

# MiniMax (国内) - https://api.minimax.io
MINIMAX_API_KEY=

# Ollama 本地 (完全免费) - https://ollama.ai
# Ollama 模型名称 (llama3/mistral/qwen 等)
LLM_MODEL=llama3
OLLAMA_HOST=http://localhost:11434

# ============ 服务器配置 ============

PORT=8000
DEBUG=false

# ============ 任务队列配置 (必须) ============

# Redis URL (任务队列必须)
# Docker: docker run -d -p 6379:6379 redis:alpine
# 本地: brew install redis && redis-server
REDIS_URL=redis://localhost:6379/0

# Celery Broker (同 Redis)
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_URL=redis://localhost:6379/0
